{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bf9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_query(X, y, method='PI', xi=0.1, kappa=2.0, grid_size=100, apply_scaling=False, title=\"Acquisition Function\"):\n",
    "    \"\"\"\n",
    "    Selects the next query point using a specified acquisition strategy.\n",
    "\n",
    "    Parameters:\n",
    "    - X: np.ndarray of shape (n_samples, 2), input features\n",
    "    - y: np.ndarray of shape (n_samples,), output values\n",
    "    - method: str, one of 'PI', 'EI', 'UCB'\n",
    "    - xi: float, exploration parameter for PI/EI\n",
    "    - kappa: float, exploration parameter for UCB\n",
    "    - grid_size: int, resolution of the search grid\n",
    "\n",
    "    Returns:\n",
    "    - next_query: np.ndarray of shape (2,), the selected input point\n",
    "    - acquisition_map: np.ndarray of shape (grid_size**2,), acquisition values\n",
    "    - X_grid: np.ndarray of shape (grid_size**2, 2), grid points evaluated\n",
    "    \"\"\"\n",
    "    if apply_scaling == True:\n",
    "        scaler = StandardScaler()\n",
    "        y_scaled = scaler.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "        y = y_scaled\n",
    "        #X_min = X.min(axis=0)\n",
    "        #X_max = X.max(axis=0)\n",
    "        #X = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "    # Fit GP model\n",
    "    kernel = RBF(length_scale=0.1, length_scale_bounds='fixed')\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-10)\n",
    "    gp.fit(X, y)\n",
    "\n",
    "    # Create grid over [0,1] x [0,1]\n",
    "    x1 = np.linspace(0, 1, grid_size)\n",
    "    x2 = np.linspace(0, 1, grid_size)\n",
    "    x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
    "    X_grid = np.column_stack([x1_grid.ravel(), x2_grid.ravel()])\n",
    "\n",
    "    # Predict GP mean and std\n",
    "    mean, std = gp.predict(X_grid, return_std=True)\n",
    "\n",
    "    # Compute acquisition function\n",
    "    if method == 'PI':\n",
    "        y_max = np.max(y)\n",
    "        z = (mean - y_max - xi) / (std + 1e-12)\n",
    "        acquisition_map = norm.cdf(z)\n",
    "\n",
    "    elif method == 'EI':\n",
    "        y_max = np.max(y)\n",
    "        z = (mean - y_max - xi) / (std + 1e-12)\n",
    "        acquisition_map = (mean - y_max - xi) * norm.cdf(z) + std * norm.pdf(z)\n",
    "\n",
    "    elif method == 'UCB':\n",
    "        acquisition_map = mean + kappa * std\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Choose from 'PI', 'EI', or 'UCB'.\")\n",
    "\n",
    "    # Select best point\n",
    "    best_index = np.argmax(acquisition_map)\n",
    "    next_query = X_grid[best_index]\n",
    "    return next_query, acquisition_map, X_grid#, mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nd_grid_1(bounds, grid_size=50, dimension=1):\n",
    "    \"\"\"\n",
    "    Create an N-dimensional grid over the given bounds with reduced density.\n",
    "    Parameters:\n",
    "    - bounds: List of (low, high) tuples for each dimension.\n",
    "    - grid_size: Number of points per axis before downsampling.\n",
    "    - dimension: Downsampling factor. The final number of points will be reduced\n",
    "                 by approximately dimension^2 in total.\n",
    "    Returns:\n",
    "    - grid: A (M x N) array of grid points, where M is reduced.\n",
    "    \"\"\"\n",
    "    print(\"Dimension of input space: \", dimension)\n",
    "    # Generate full-resolution axes\n",
    "    axes = [np.linspace(low, high, grid_size) for (low, high) in bounds]\n",
    "    print(\"Each axis has \", len(axes[0]), \" points\")\n",
    "    # Create meshgrid from full-resolution axes\n",
    "    mesh = np.meshgrid(*axes)\n",
    "    print\n",
    "    if dimension is not None:\n",
    "        # Downsample each axis by selecting every `dimension`-th point\n",
    "        reduced_axes = [axis[::dimension] for axis in axes]\n",
    "        # Create meshgrid from reduced axes\n",
    "        mesh = np.meshgrid(*reduced_axes, indexing='ij')\n",
    "    # Flatten meshgrid into (M x N) grid\n",
    "    grid = np.stack([m.ravel() for m in mesh], axis=-1)\n",
    "    print(\"Function will evaluate accross : \", grid.shape[0], \" points\")\n",
    "    return grid\n",
    "\n",
    "def create_nd_grid(bounds, grid_size=50, dimension=1):\n",
    "    \"\"\"\n",
    "    Create an N-dimensional grid over the given bounds with reduced density.\n",
    "    Parameters:\n",
    "    - bounds: List of (low, high) tuples for each dimension.\n",
    "    - grid_size: Number of points per axis before downsampling.\n",
    "    - dimension: Downsampling factor. The final number of points will be reduced\n",
    "                 by approximately dimension^2 in total.\n",
    "    Returns:\n",
    "    - grid: A (M x N) array of grid points, where M is reduced.\n",
    "    \"\"\"\n",
    "    print(\"Dimension of input space:\", len(bounds))\n",
    "    axes = [np.linspace(low, high, grid_size) for (low, high) in bounds]\n",
    "    print(\"Each axis has\", len(axes[0]), \"points before downsampling\")\n",
    "\n",
    "    # Downsample each axis\n",
    "    reduced_axes = [axis[::dimension] for axis in axes]\n",
    "    print(\"Each axis has\", len(reduced_axes[0]), \"points after downsampling\")\n",
    "\n",
    "    # Create meshgrid from reduced axes\n",
    "    mesh = np.meshgrid(*reduced_axes, indexing='ij')\n",
    "\n",
    "    # Flatten meshgrid into (M x N) grid\n",
    "    grid = np.stack([m.ravel() for m in mesh], axis=-1)\n",
    "    print(\"Function will evaluate across:\", grid.shape[0], \"points\")\n",
    "\n",
    "    return grid\n",
    "\n",
    "def select_next_query_multi(X, y, method='PI', xi=0.1, kappa=2.0, grid_size=100, dimension=None,\n",
    "                      apply_scaling=False, title=\"Acquisition Function\"):\n",
    "    \"\"\"\n",
    "    Selects the next query point using a specified acquisition strategy.\n",
    "\n",
    "    Parameters:\n",
    "    - X: np.ndarray of shape (n_samples, n_features), input features\n",
    "    - y: np.ndarray of shape (n_samples,), output values\n",
    "    - method: str, one of 'PI', 'EI', 'UCB'\n",
    "    - xi: float, exploration parameter for PI/EI\n",
    "    - kappa: float, exploration parameter for UCB\n",
    "    - grid_size: int, resolution of the search grid\n",
    "    - apply_scaling: bool, whether to standardize y\n",
    "    - visualize: bool, whether to plot acquisition surface (only for 2D)\n",
    "    - title: str, plot title\n",
    "\n",
    "    Returns:\n",
    "    - next_query: np.ndarray of shape (n_features,), the selected input point\n",
    "    - acquisition_map: np.ndarray of shape (grid_size**n,), acquisition values\n",
    "    - X_grid: np.ndarray of shape (grid_size**n, n_features), grid points evaluated\n",
    "    - mean: np.ndarray of shape (grid_size**n,), GP mean predictions\n",
    "    - std: np.ndarray of shape (grid_size**n,), GP std predictions\n",
    "    \"\"\"\n",
    "    if apply_scaling:\n",
    "        scaler = StandardScaler()\n",
    "        y = scaler.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "    n_features = X.shape[1]\n",
    "    print(\"Number of features: \", n_features)\n",
    "    bounds = [(0, 1)] * n_features\n",
    "    X_grid = create_nd_grid(bounds, grid_size, dimension)\n",
    "\n",
    "    kernel = RBF(length_scale=0.1, length_scale_bounds='fixed')\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, alpha=1e-10)\n",
    "    gp.fit(X, y)\n",
    "\n",
    "    mean, std = gp.predict(X_grid, return_std=True)\n",
    "    print(\"Mean \", len(mean))\n",
    "    print(\"Std  \", len(std))\n",
    "\n",
    "    if method == 'PI':\n",
    "        y_max = np.max(y)\n",
    "        z = (mean - y_max - xi) / (std + 1e-12)\n",
    "        acquisition_map = norm.cdf(z)\n",
    "\n",
    "    elif method == 'EI':\n",
    "        y_max = np.max(y)\n",
    "        z = (mean - y_max - xi) / (std + 1e-12)\n",
    "        acquisition_map = (mean - y_max - xi) * norm.cdf(z) + std * norm.pdf(z)\n",
    "\n",
    "    elif method == 'UCB':\n",
    "        acquisition_map = mean + kappa * std\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Choose from 'PI', 'EI', or 'UCB'.\")\n",
    "\n",
    "    best_index = np.argmax(acquisition_map)\n",
    "    next_query = X_grid[best_index]\n",
    "\n",
    "    return next_query, acquisition_map, X_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acquisition_heatmap(\n",
    "    X,                   # shape (n_samples, 2): queried points\n",
    "    acquisition_map,     # shape (grid_size**2,): acquisition values\n",
    "    X_grid,              # shape (grid_size**2, 2): grid points\n",
    "    next_query=None,     # shape (2,), optional: next query point\n",
    "    title='Acquisition Heatmap',\n",
    "    cmap='viridis',\n",
    "    color_range=(-3, 1), # default color scale for consistency\n",
    "    save_path=None       # optional: path to save plot\n",
    "):\n",
    "    grid_size = int(np.sqrt(len(acquisition_map)))\n",
    "    acquisition_2d = acquisition_map.reshape(grid_size, grid_size)\n",
    "\n",
    "    # Compute extent from grid\n",
    "    x_min, x_max = X_grid[:, 0].min(), X_grid[:, 0].max()\n",
    "    y_min, y_max = X_grid[:, 1].min(), X_grid[:, 1].max()\n",
    "    extent = [x_min, x_max, y_min, y_max]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    im = plt.imshow(\n",
    "        acquisition_2d,\n",
    "        origin='lower',\n",
    "        extent=extent,\n",
    "        cmap=cmap,\n",
    "        aspect='auto',\n",
    "        vmin=color_range[0],\n",
    "        vmax=color_range[1]\n",
    "    )\n",
    "    plt.colorbar(im, label='Acquisition Value')\n",
    "\n",
    "    # Queried points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c='white', edgecolors='black', label='Queried Points')\n",
    "\n",
    "    # Next query\n",
    "    if next_query is not None:\n",
    "        plt.plot(next_query[0], next_query[1], 'r*', markersize=14, label='Next Query')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d169463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_query_result(method, param, x, y_val):\n",
    "    \"\"\"Stores a query result with dimensionality awareness.\"\"\"\n",
    "    query_results.append({\n",
    "        'method': method,\n",
    "        'xi': param if method in ['PI', 'EI'] else None,\n",
    "        'kappa': param if method == 'UCB' else None,\n",
    "        'x': np.array(x),\n",
    "        'y': y_val,\n",
    "        'dim': len(x)\n",
    "    })\n",
    "\n",
    "def log_query_candidate(method, param, x, acq_score):\n",
    "    \"\"\"Stores a candidate query point and its acquisition score.\"\"\"\n",
    "    query_results.append({\n",
    "        'method': method,\n",
    "        'xi': param if method in ['PI', 'EI'] else None,\n",
    "        'kappa': param if method == 'UCB' else None,\n",
    "        'x': np.array(x),\n",
    "        'score': acq_score,\n",
    "        'dim': len(x)\n",
    "    })\n",
    "\n",
    "def find_best_query(results):\n",
    "    print(\"Total number of points to evaluate:\", len(results))\n",
    "    \"\"\"Returns the best query point from a collection of arbitrary dimensions.\"\"\"\n",
    "    if not results:\n",
    "        raise ValueError(\"No results to evaluate.\")\n",
    "\n",
    "    best = max(results, key=lambda r: r['y'])\n",
    "\n",
    "    print(\"üîç Best query found:\")\n",
    "    print(f\"Method: {best['method']}\")\n",
    "    if best['method'] in ['PI', 'EI']:\n",
    "        print(f\"xi: {best['xi']}\")\n",
    "    else:\n",
    "        print(f\"kappa: {best['kappa']}\")\n",
    "    print(f\"Dimensions: {best['dim']}\")\n",
    "    print(f\"x: {np.array2string(best['x'], precision=4, separator=', ')}\")\n",
    "    print(f\"f(x): {best['y']:.4f}\")\n",
    "\n",
    "    return best\n",
    "\n",
    "def find_best_candidate(results):\n",
    "    print(\"Total number of points to evaluate:\", len(results))\n",
    "    for item in results:\n",
    "        print(item)\n",
    "    \"\"\"Returns the best candidate point based on acquisition score.\"\"\"\n",
    "    if not results:\n",
    "        raise ValueError(\"No candidates to evaluate.\")\n",
    "\n",
    "    best = max(results, key=lambda r: r['score'])\n",
    "\n",
    "    print(\"üîç Best candidate (highest acquisition score):\")\n",
    "    print(f\"Method: {best['method']}\")\n",
    "    if best['method'] in ['PI', 'EI']:\n",
    "        print(f\"xi: {best['xi']}\")\n",
    "    else:\n",
    "        print(f\"kappa: {best['kappa']}\")\n",
    "    print(f\"Dimensions: {best['dim']}\")\n",
    "    print(f\"x: {np.array2string(best['x'], precision=4, separator=', ')}\")\n",
    "    print(f\"Score: {best['score']:.6f}\")\n",
    "\n",
    "    return best"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
